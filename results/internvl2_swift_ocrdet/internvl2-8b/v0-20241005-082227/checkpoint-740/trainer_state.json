{
  "best_metric": 1.28633964,
  "best_model_checkpoint": "/home/lgd/e_commerce_lmm/results/internvl2_swift_ocrdet/internvl2-8b/v0-20241005-082227/checkpoint-740",
  "epoch": 4.991568296795953,
  "eval_steps": 1000,
  "global_step": 740,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "acc": 0.55080837,
      "epoch": 0.006745362563237774,
      "grad_norm": 7.8125,
      "learning_rate": 2.702702702702703e-06,
      "loss": 4.15771818,
      "memory(GiB)": 45.46,
      "step": 1,
      "train_speed(iter/s)": 0.038746
    },
    {
      "acc": 0.56241298,
      "epoch": 0.03372681281618887,
      "grad_norm": 7.5625,
      "learning_rate": 1.3513513513513515e-05,
      "loss": 3.7542944,
      "memory(GiB)": 45.46,
      "step": 5,
      "train_speed(iter/s)": 0.072926
    },
    {
      "acc": 0.71412096,
      "epoch": 0.06745362563237774,
      "grad_norm": 1.546875,
      "learning_rate": 2.702702702702703e-05,
      "loss": 2.01606884,
      "memory(GiB)": 45.46,
      "step": 10,
      "train_speed(iter/s)": 0.083059
    },
    {
      "acc": 0.74948835,
      "epoch": 0.10118043844856661,
      "grad_norm": 3.09375,
      "learning_rate": 4.0540540540540545e-05,
      "loss": 1.57241554,
      "memory(GiB)": 45.46,
      "step": 15,
      "train_speed(iter/s)": 0.088262
    },
    {
      "acc": 0.75693622,
      "epoch": 0.13490725126475547,
      "grad_norm": 1.0546875,
      "learning_rate": 5.405405405405406e-05,
      "loss": 1.40378456,
      "memory(GiB)": 45.46,
      "step": 20,
      "train_speed(iter/s)": 0.090268
    },
    {
      "acc": 0.75925961,
      "epoch": 0.16863406408094436,
      "grad_norm": 1.2421875,
      "learning_rate": 6.756756756756757e-05,
      "loss": 1.37430878,
      "memory(GiB)": 45.46,
      "step": 25,
      "train_speed(iter/s)": 0.091679
    },
    {
      "acc": 0.75641127,
      "epoch": 0.20236087689713322,
      "grad_norm": 1.53125,
      "learning_rate": 8.108108108108109e-05,
      "loss": 1.37164602,
      "memory(GiB)": 45.46,
      "step": 30,
      "train_speed(iter/s)": 0.09248
    },
    {
      "acc": 0.75983725,
      "epoch": 0.23608768971332209,
      "grad_norm": 1.2421875,
      "learning_rate": 9.45945945945946e-05,
      "loss": 1.28958473,
      "memory(GiB)": 45.46,
      "step": 35,
      "train_speed(iter/s)": 0.093636
    },
    {
      "acc": 0.75276418,
      "epoch": 0.26981450252951095,
      "grad_norm": 2.171875,
      "learning_rate": 9.99955067031769e-05,
      "loss": 1.36204414,
      "memory(GiB)": 45.46,
      "step": 40,
      "train_speed(iter/s)": 0.093622
    },
    {
      "acc": 0.75773563,
      "epoch": 0.30354131534569984,
      "grad_norm": 1.28125,
      "learning_rate": 9.996805059158207e-05,
      "loss": 1.34109602,
      "memory(GiB)": 45.46,
      "step": 45,
      "train_speed(iter/s)": 0.093719
    },
    {
      "acc": 0.76544752,
      "epoch": 0.3372681281618887,
      "grad_norm": 1.953125,
      "learning_rate": 9.991564833502943e-05,
      "loss": 1.28466845,
      "memory(GiB)": 45.46,
      "step": 50,
      "train_speed(iter/s)": 0.094294
    },
    {
      "acc": 0.75853386,
      "epoch": 0.37099494097807756,
      "grad_norm": 1.953125,
      "learning_rate": 9.983832609492155e-05,
      "loss": 1.263097,
      "memory(GiB)": 45.46,
      "step": 55,
      "train_speed(iter/s)": 0.094354
    },
    {
      "acc": 0.77540998,
      "epoch": 0.40472175379426645,
      "grad_norm": 1.375,
      "learning_rate": 9.973612247376118e-05,
      "loss": 1.22826815,
      "memory(GiB)": 45.46,
      "step": 60,
      "train_speed(iter/s)": 0.094129
    },
    {
      "acc": 0.76900625,
      "epoch": 0.43844856661045534,
      "grad_norm": 1.3828125,
      "learning_rate": 9.960908849587922e-05,
      "loss": 1.22618656,
      "memory(GiB)": 52.69,
      "step": 65,
      "train_speed(iter/s)": 0.094205
    },
    {
      "acc": 0.76371441,
      "epoch": 0.47217537942664417,
      "grad_norm": 1.609375,
      "learning_rate": 9.945728758196129e-05,
      "loss": 1.25284948,
      "memory(GiB)": 52.69,
      "step": 70,
      "train_speed(iter/s)": 0.094249
    },
    {
      "acc": 0.76523438,
      "epoch": 0.5059021922428331,
      "grad_norm": 1.875,
      "learning_rate": 9.928079551738543e-05,
      "loss": 1.26649971,
      "memory(GiB)": 52.69,
      "step": 75,
      "train_speed(iter/s)": 0.094149
    },
    {
      "acc": 0.77246847,
      "epoch": 0.5396290050590219,
      "grad_norm": 1.703125,
      "learning_rate": 9.907970041438684e-05,
      "loss": 1.20666904,
      "memory(GiB)": 52.69,
      "step": 80,
      "train_speed(iter/s)": 0.094292
    },
    {
      "acc": 0.77314949,
      "epoch": 0.5733558178752108,
      "grad_norm": 2.515625,
      "learning_rate": 9.885410266806857e-05,
      "loss": 1.16832008,
      "memory(GiB)": 52.69,
      "step": 85,
      "train_speed(iter/s)": 0.094572
    },
    {
      "acc": 0.77541714,
      "epoch": 0.6070826306913997,
      "grad_norm": 1.6484375,
      "learning_rate": 9.860411490628016e-05,
      "loss": 1.16045437,
      "memory(GiB)": 52.69,
      "step": 90,
      "train_speed(iter/s)": 0.094465
    },
    {
      "acc": 0.77402205,
      "epoch": 0.6408094435075885,
      "grad_norm": 1.9453125,
      "learning_rate": 9.832986193338897e-05,
      "loss": 1.145541,
      "memory(GiB)": 52.69,
      "step": 95,
      "train_speed(iter/s)": 0.094543
    },
    {
      "acc": 0.7808444,
      "epoch": 0.6745362563237775,
      "grad_norm": 1.8046875,
      "learning_rate": 9.803148066797269e-05,
      "loss": 1.11463404,
      "memory(GiB)": 52.69,
      "step": 100,
      "train_speed(iter/s)": 0.094726
    },
    {
      "acc": 0.78036861,
      "epoch": 0.7082630691399663,
      "grad_norm": 1.8125,
      "learning_rate": 9.770912007446385e-05,
      "loss": 1.09661007,
      "memory(GiB)": 52.69,
      "step": 105,
      "train_speed(iter/s)": 0.094761
    },
    {
      "acc": 0.77785406,
      "epoch": 0.7419898819561551,
      "grad_norm": 2.828125,
      "learning_rate": 9.736294108878044e-05,
      "loss": 1.13015947,
      "memory(GiB)": 52.69,
      "step": 110,
      "train_speed(iter/s)": 0.094814
    },
    {
      "acc": 0.77437725,
      "epoch": 0.7757166947723441,
      "grad_norm": 1.6875,
      "learning_rate": 9.69931165379801e-05,
      "loss": 1.15455027,
      "memory(GiB)": 52.69,
      "step": 115,
      "train_speed(iter/s)": 0.095072
    },
    {
      "acc": 0.77387695,
      "epoch": 0.8094435075885329,
      "grad_norm": 1.5234375,
      "learning_rate": 9.65998310539775e-05,
      "loss": 1.1195364,
      "memory(GiB)": 52.69,
      "step": 120,
      "train_speed(iter/s)": 0.095111
    },
    {
      "acc": 0.77525072,
      "epoch": 0.8431703204047217,
      "grad_norm": 1.921875,
      "learning_rate": 9.618328098136838e-05,
      "loss": 1.12056274,
      "memory(GiB)": 52.69,
      "step": 125,
      "train_speed(iter/s)": 0.095336
    },
    {
      "acc": 0.77502255,
      "epoch": 0.8768971332209107,
      "grad_norm": 1.8671875,
      "learning_rate": 9.57436742794061e-05,
      "loss": 1.13439465,
      "memory(GiB)": 52.69,
      "step": 130,
      "train_speed(iter/s)": 0.095242
    },
    {
      "acc": 0.7862031,
      "epoch": 0.9106239460370995,
      "grad_norm": 1.6640625,
      "learning_rate": 9.52812304181797e-05,
      "loss": 1.07940321,
      "memory(GiB)": 52.69,
      "step": 135,
      "train_speed(iter/s)": 0.095245
    },
    {
      "acc": 0.77837467,
      "epoch": 0.9443507588532883,
      "grad_norm": 2.28125,
      "learning_rate": 9.47961802690452e-05,
      "loss": 1.10889463,
      "memory(GiB)": 52.69,
      "step": 140,
      "train_speed(iter/s)": 0.095254
    },
    {
      "acc": 0.78822455,
      "epoch": 0.9780775716694773,
      "grad_norm": 1.7890625,
      "learning_rate": 9.42887659893649e-05,
      "loss": 1.06551409,
      "memory(GiB)": 52.69,
      "step": 145,
      "train_speed(iter/s)": 0.095239
    },
    {
      "acc": 0.79054828,
      "epoch": 1.0118043844856661,
      "grad_norm": 2.53125,
      "learning_rate": 9.375924090161237e-05,
      "loss": 1.0489563,
      "memory(GiB)": 52.69,
      "step": 150,
      "train_speed(iter/s)": 0.095138
    },
    {
      "acc": 0.78850727,
      "epoch": 1.045531197301855,
      "grad_norm": 2.15625,
      "learning_rate": 9.32078693669032e-05,
      "loss": 1.04103899,
      "memory(GiB)": 52.69,
      "step": 155,
      "train_speed(iter/s)": 0.095285
    },
    {
      "acc": 0.77680187,
      "epoch": 1.0792580101180438,
      "grad_norm": 1.9765625,
      "learning_rate": 9.263492665301485e-05,
      "loss": 1.08647156,
      "memory(GiB)": 57.51,
      "step": 160,
      "train_speed(iter/s)": 0.0952
    },
    {
      "acc": 0.78218641,
      "epoch": 1.1129848229342327,
      "grad_norm": 1.7421875,
      "learning_rate": 9.204069879696145e-05,
      "loss": 1.09364376,
      "memory(GiB)": 57.51,
      "step": 165,
      "train_speed(iter/s)": 0.095115
    },
    {
      "acc": 0.79127598,
      "epoch": 1.1467116357504217,
      "grad_norm": 1.859375,
      "learning_rate": 9.142548246219212e-05,
      "loss": 1.05153837,
      "memory(GiB)": 57.51,
      "step": 170,
      "train_speed(iter/s)": 0.095126
    },
    {
      "acc": 0.77340059,
      "epoch": 1.1804384485666104,
      "grad_norm": 1.546875,
      "learning_rate": 9.078958479048419e-05,
      "loss": 1.11050653,
      "memory(GiB)": 57.51,
      "step": 175,
      "train_speed(iter/s)": 0.095124
    },
    {
      "acc": 0.78772984,
      "epoch": 1.2141652613827993,
      "grad_norm": 2.671875,
      "learning_rate": 9.013332324860509e-05,
      "loss": 1.05247412,
      "memory(GiB)": 64.74,
      "step": 180,
      "train_speed(iter/s)": 0.095135
    },
    {
      "acc": 0.79385548,
      "epoch": 1.2478920741989883,
      "grad_norm": 3.015625,
      "learning_rate": 8.945702546981969e-05,
      "loss": 1.01918354,
      "memory(GiB)": 64.74,
      "step": 185,
      "train_speed(iter/s)": 0.095024
    },
    {
      "acc": 0.78804569,
      "epoch": 1.281618887015177,
      "grad_norm": 1.7421875,
      "learning_rate": 8.8761029090322e-05,
      "loss": 1.03999062,
      "memory(GiB)": 64.74,
      "step": 190,
      "train_speed(iter/s)": 0.095022
    },
    {
      "acc": 0.78580475,
      "epoch": 1.315345699831366,
      "grad_norm": 2.25,
      "learning_rate": 8.804568158067307e-05,
      "loss": 1.01731758,
      "memory(GiB)": 64.74,
      "step": 195,
      "train_speed(iter/s)": 0.095029
    },
    {
      "acc": 0.79188356,
      "epoch": 1.3490725126475547,
      "grad_norm": 1.953125,
      "learning_rate": 8.731134007232911e-05,
      "loss": 1.03056927,
      "memory(GiB)": 64.74,
      "step": 200,
      "train_speed(iter/s)": 0.095071
    },
    {
      "acc": 0.79281263,
      "epoch": 1.3827993254637436,
      "grad_norm": 1.78125,
      "learning_rate": 8.655837117934642e-05,
      "loss": 1.02159767,
      "memory(GiB)": 64.74,
      "step": 205,
      "train_speed(iter/s)": 0.095046
    },
    {
      "acc": 0.79211359,
      "epoch": 1.4165261382799326,
      "grad_norm": 2.15625,
      "learning_rate": 8.578715081535249e-05,
      "loss": 1.0024538,
      "memory(GiB)": 64.74,
      "step": 210,
      "train_speed(iter/s)": 0.095117
    },
    {
      "acc": 0.78596573,
      "epoch": 1.4502529510961213,
      "grad_norm": 2.140625,
      "learning_rate": 8.499806400587391e-05,
      "loss": 1.03557777,
      "memory(GiB)": 67.16,
      "step": 215,
      "train_speed(iter/s)": 0.094983
    },
    {
      "acc": 0.79595299,
      "epoch": 1.4839797639123102,
      "grad_norm": 1.7890625,
      "learning_rate": 8.419150469611572e-05,
      "loss": 0.98584862,
      "memory(GiB)": 67.16,
      "step": 220,
      "train_speed(iter/s)": 0.094993
    },
    {
      "acc": 0.79876747,
      "epoch": 1.5177065767284992,
      "grad_norm": 1.796875,
      "learning_rate": 8.336787555428729e-05,
      "loss": 0.96336107,
      "memory(GiB)": 67.16,
      "step": 225,
      "train_speed(iter/s)": 0.095003
    },
    {
      "acc": 0.79244576,
      "epoch": 1.551433389544688,
      "grad_norm": 4.25,
      "learning_rate": 8.252758777057355e-05,
      "loss": 0.99505024,
      "memory(GiB)": 67.16,
      "step": 230,
      "train_speed(iter/s)": 0.095044
    },
    {
      "acc": 0.78987737,
      "epoch": 1.5851602023608768,
      "grad_norm": 2.625,
      "learning_rate": 8.16710608518516e-05,
      "loss": 1.00737028,
      "memory(GiB)": 67.16,
      "step": 235,
      "train_speed(iter/s)": 0.095177
    },
    {
      "acc": 0.79187374,
      "epoch": 1.6188870151770658,
      "grad_norm": 2.203125,
      "learning_rate": 8.079872241225535e-05,
      "loss": 0.99554482,
      "memory(GiB)": 67.16,
      "step": 240,
      "train_speed(iter/s)": 0.095116
    },
    {
      "acc": 0.79670076,
      "epoch": 1.6526138279932545,
      "grad_norm": 1.5078125,
      "learning_rate": 7.991100795969248e-05,
      "loss": 1.01088009,
      "memory(GiB)": 67.16,
      "step": 245,
      "train_speed(iter/s)": 0.095151
    },
    {
      "acc": 0.79615316,
      "epoch": 1.6863406408094435,
      "grad_norm": 2.984375,
      "learning_rate": 7.900836067842079e-05,
      "loss": 0.95661726,
      "memory(GiB)": 67.16,
      "step": 250,
      "train_speed(iter/s)": 0.09514
    },
    {
      "acc": 0.7975378,
      "epoch": 1.7200674536256324,
      "grad_norm": 2.015625,
      "learning_rate": 7.8091231207792e-05,
      "loss": 0.96661224,
      "memory(GiB)": 67.16,
      "step": 255,
      "train_speed(iter/s)": 0.095102
    },
    {
      "acc": 0.79675608,
      "epoch": 1.7537942664418211,
      "grad_norm": 2.6875,
      "learning_rate": 7.716007741727368e-05,
      "loss": 0.97118158,
      "memory(GiB)": 67.16,
      "step": 260,
      "train_speed(iter/s)": 0.095088
    },
    {
      "acc": 0.79661207,
      "epoch": 1.78752107925801,
      "grad_norm": 1.8125,
      "learning_rate": 7.621536417786159e-05,
      "loss": 0.9765316,
      "memory(GiB)": 67.16,
      "step": 265,
      "train_speed(iter/s)": 0.095094
    },
    {
      "acc": 0.80644178,
      "epoch": 1.821247892074199,
      "grad_norm": 2.03125,
      "learning_rate": 7.52575631299967e-05,
      "loss": 0.90905399,
      "memory(GiB)": 67.16,
      "step": 270,
      "train_speed(iter/s)": 0.095085
    },
    {
      "acc": 0.79763432,
      "epoch": 1.8549747048903877,
      "grad_norm": 2.1875,
      "learning_rate": 7.428715244810238e-05,
      "loss": 0.96538525,
      "memory(GiB)": 67.16,
      "step": 275,
      "train_speed(iter/s)": 0.095106
    },
    {
      "acc": 0.80126438,
      "epoch": 1.8887015177065767,
      "grad_norm": 2.078125,
      "learning_rate": 7.330461660185986e-05,
      "loss": 0.92794476,
      "memory(GiB)": 67.16,
      "step": 280,
      "train_speed(iter/s)": 0.095039
    },
    {
      "acc": 0.80803289,
      "epoch": 1.9224283305227656,
      "grad_norm": 2.25,
      "learning_rate": 7.231044611434049e-05,
      "loss": 0.92943707,
      "memory(GiB)": 67.16,
      "step": 285,
      "train_speed(iter/s)": 0.095132
    },
    {
      "acc": 0.81046085,
      "epoch": 1.9561551433389543,
      "grad_norm": 2.328125,
      "learning_rate": 7.130513731711616e-05,
      "loss": 0.89614353,
      "memory(GiB)": 67.16,
      "step": 290,
      "train_speed(iter/s)": 0.095081
    },
    {
      "acc": 0.81140385,
      "epoch": 1.9898819561551433,
      "grad_norm": 2.171875,
      "learning_rate": 7.028919210246975e-05,
      "loss": 0.89171839,
      "memory(GiB)": 67.16,
      "step": 295,
      "train_speed(iter/s)": 0.095139
    },
    {
      "acc": 0.80904961,
      "epoch": 2.0236087689713322,
      "grad_norm": 2.09375,
      "learning_rate": 6.92631176728295e-05,
      "loss": 0.91836987,
      "memory(GiB)": 67.16,
      "step": 300,
      "train_speed(iter/s)": 0.095134
    },
    {
      "acc": 0.79619436,
      "epoch": 2.057335581787521,
      "grad_norm": 3.015625,
      "learning_rate": 6.822742628755228e-05,
      "loss": 0.98966103,
      "memory(GiB)": 67.16,
      "step": 305,
      "train_speed(iter/s)": 0.09513
    },
    {
      "acc": 0.81669455,
      "epoch": 2.09106239460371,
      "grad_norm": 2.234375,
      "learning_rate": 6.718263500718218e-05,
      "loss": 0.83540974,
      "memory(GiB)": 67.16,
      "step": 310,
      "train_speed(iter/s)": 0.095118
    },
    {
      "acc": 0.8174159,
      "epoch": 2.124789207419899,
      "grad_norm": 7.1875,
      "learning_rate": 6.61292654353124e-05,
      "loss": 0.84015617,
      "memory(GiB)": 67.16,
      "step": 315,
      "train_speed(iter/s)": 0.095119
    },
    {
      "acc": 0.81472292,
      "epoch": 2.1585160202360876,
      "grad_norm": 2.015625,
      "learning_rate": 6.506784345817867e-05,
      "loss": 0.86721411,
      "memory(GiB)": 67.16,
      "step": 320,
      "train_speed(iter/s)": 0.095075
    },
    {
      "acc": 0.80994377,
      "epoch": 2.1922428330522767,
      "grad_norm": 3.09375,
      "learning_rate": 6.399889898211494e-05,
      "loss": 0.872124,
      "memory(GiB)": 67.16,
      "step": 325,
      "train_speed(iter/s)": 0.095085
    },
    {
      "acc": 0.81256809,
      "epoch": 2.2259696458684655,
      "grad_norm": 1.9296875,
      "learning_rate": 6.292296566900187e-05,
      "loss": 0.85876083,
      "memory(GiB)": 67.16,
      "step": 330,
      "train_speed(iter/s)": 0.095145
    },
    {
      "acc": 0.82309027,
      "epoch": 2.259696458684654,
      "grad_norm": 2.09375,
      "learning_rate": 6.184058066984045e-05,
      "loss": 0.81562805,
      "memory(GiB)": 67.16,
      "step": 335,
      "train_speed(iter/s)": 0.095217
    },
    {
      "acc": 0.81394491,
      "epoch": 2.2934232715008434,
      "grad_norm": 2.328125,
      "learning_rate": 6.075228435658379e-05,
      "loss": 0.84183064,
      "memory(GiB)": 67.16,
      "step": 340,
      "train_speed(iter/s)": 0.095171
    },
    {
      "acc": 0.81460266,
      "epoch": 2.327150084317032,
      "grad_norm": 2.21875,
      "learning_rate": 5.965862005236067e-05,
      "loss": 0.86760025,
      "memory(GiB)": 67.16,
      "step": 345,
      "train_speed(iter/s)": 0.095235
    },
    {
      "acc": 0.81109095,
      "epoch": 2.360876897133221,
      "grad_norm": 2.765625,
      "learning_rate": 5.856013376022595e-05,
      "loss": 0.88138123,
      "memory(GiB)": 67.16,
      "step": 350,
      "train_speed(iter/s)": 0.095204
    },
    {
      "acc": 0.82133856,
      "epoch": 2.39460370994941,
      "grad_norm": 2.84375,
      "learning_rate": 5.7457373890572944e-05,
      "loss": 0.81961441,
      "memory(GiB)": 67.16,
      "step": 355,
      "train_speed(iter/s)": 0.095245
    },
    {
      "acc": 0.82803726,
      "epoch": 2.4283305227655987,
      "grad_norm": 2.671875,
      "learning_rate": 5.6350890987343944e-05,
      "loss": 0.78365765,
      "memory(GiB)": 67.16,
      "step": 360,
      "train_speed(iter/s)": 0.095297
    },
    {
      "acc": 0.82511864,
      "epoch": 2.4620573355817874,
      "grad_norm": 2.96875,
      "learning_rate": 5.524123745317567e-05,
      "loss": 0.80421162,
      "memory(GiB)": 67.16,
      "step": 365,
      "train_speed(iter/s)": 0.095422
    },
    {
      "acc": 0.8294796,
      "epoch": 2.4957841483979766,
      "grad_norm": 2.140625,
      "learning_rate": 5.4128967273616625e-05,
      "loss": 0.79710369,
      "memory(GiB)": 67.16,
      "step": 370,
      "train_speed(iter/s)": 0.095395
    },
    {
      "acc": 0.81665392,
      "epoch": 2.5295109612141653,
      "grad_norm": 3.046875,
      "learning_rate": 5.301463574055441e-05,
      "loss": 0.8282093,
      "memory(GiB)": 67.16,
      "step": 375,
      "train_speed(iter/s)": 0.095443
    },
    {
      "acc": 0.83168602,
      "epoch": 2.563237774030354,
      "grad_norm": 2.484375,
      "learning_rate": 5.189879917499067e-05,
      "loss": 0.77596402,
      "memory(GiB)": 67.16,
      "step": 380,
      "train_speed(iter/s)": 0.095441
    },
    {
      "acc": 0.83156509,
      "epoch": 2.5969645868465427,
      "grad_norm": 2.125,
      "learning_rate": 5.07820146493023e-05,
      "loss": 0.76672144,
      "memory(GiB)": 67.16,
      "step": 385,
      "train_speed(iter/s)": 0.095496
    },
    {
      "acc": 0.83759823,
      "epoch": 2.630691399662732,
      "grad_norm": 1.9609375,
      "learning_rate": 4.966483970912769e-05,
      "loss": 0.73667316,
      "memory(GiB)": 67.16,
      "step": 390,
      "train_speed(iter/s)": 0.095433
    },
    {
      "acc": 0.82663422,
      "epoch": 2.6644182124789206,
      "grad_norm": 2.71875,
      "learning_rate": 4.854783209501646e-05,
      "loss": 0.8049736,
      "memory(GiB)": 67.16,
      "step": 395,
      "train_speed(iter/s)": 0.095434
    },
    {
      "acc": 0.83647137,
      "epoch": 2.6981450252951094,
      "grad_norm": 2.375,
      "learning_rate": 4.7431549463982065e-05,
      "loss": 0.72140102,
      "memory(GiB)": 67.16,
      "step": 400,
      "train_speed(iter/s)": 0.095388
    },
    {
      "acc": 0.83148136,
      "epoch": 2.7318718381112985,
      "grad_norm": 2.1875,
      "learning_rate": 4.6316549111096e-05,
      "loss": 0.77011833,
      "memory(GiB)": 67.16,
      "step": 405,
      "train_speed(iter/s)": 0.095418
    },
    {
      "acc": 0.83345098,
      "epoch": 2.7655986509274872,
      "grad_norm": 3.25,
      "learning_rate": 4.5203387691262774e-05,
      "loss": 0.73494058,
      "memory(GiB)": 67.16,
      "step": 410,
      "train_speed(iter/s)": 0.095404
    },
    {
      "acc": 0.83947401,
      "epoch": 2.799325463743676,
      "grad_norm": 2.25,
      "learning_rate": 4.40926209413145e-05,
      "loss": 0.71205626,
      "memory(GiB)": 67.16,
      "step": 415,
      "train_speed(iter/s)": 0.0954
    },
    {
      "acc": 0.83839035,
      "epoch": 2.833052276559865,
      "grad_norm": 2.859375,
      "learning_rate": 4.2984803402563654e-05,
      "loss": 0.70324759,
      "memory(GiB)": 67.16,
      "step": 420,
      "train_speed(iter/s)": 0.095401
    },
    {
      "acc": 0.84551487,
      "epoch": 2.866779089376054,
      "grad_norm": 2.453125,
      "learning_rate": 4.188048814395293e-05,
      "loss": 0.68179874,
      "memory(GiB)": 67.16,
      "step": 425,
      "train_speed(iter/s)": 0.095397
    },
    {
      "acc": 0.84067631,
      "epoch": 2.9005059021922426,
      "grad_norm": 3.28125,
      "learning_rate": 4.0780226485939974e-05,
      "loss": 0.72457981,
      "memory(GiB)": 67.16,
      "step": 430,
      "train_speed(iter/s)": 0.095428
    },
    {
      "acc": 0.84441595,
      "epoch": 2.9342327150084317,
      "grad_norm": 2.59375,
      "learning_rate": 3.968456772525515e-05,
      "loss": 0.72381516,
      "memory(GiB)": 67.16,
      "step": 435,
      "train_speed(iter/s)": 0.095454
    },
    {
      "acc": 0.84193344,
      "epoch": 2.9679595278246205,
      "grad_norm": 2.453125,
      "learning_rate": 3.8594058860669584e-05,
      "loss": 0.68665028,
      "memory(GiB)": 67.16,
      "step": 440,
      "train_speed(iter/s)": 0.095464
    },
    {
      "acc": 0.84967213,
      "epoch": 3.0016863406408096,
      "grad_norm": 3.984375,
      "learning_rate": 3.750924431991041e-05,
      "loss": 0.68512249,
      "memory(GiB)": 67.16,
      "step": 445,
      "train_speed(iter/s)": 0.095411
    },
    {
      "acc": 0.85528374,
      "epoch": 3.0354131534569984,
      "grad_norm": 2.53125,
      "learning_rate": 3.643066568785969e-05,
      "loss": 0.64550128,
      "memory(GiB)": 67.16,
      "step": 450,
      "train_speed(iter/s)": 0.095383
    },
    {
      "acc": 0.85808334,
      "epoch": 3.069139966273187,
      "grad_norm": 2.71875,
      "learning_rate": 3.5358861436172485e-05,
      "loss": 0.63662553,
      "memory(GiB)": 67.16,
      "step": 455,
      "train_speed(iter/s)": 0.09541
    },
    {
      "acc": 0.85843334,
      "epoch": 3.1028667790893762,
      "grad_norm": 3.09375,
      "learning_rate": 3.4294366654449336e-05,
      "loss": 0.6303299,
      "memory(GiB)": 67.16,
      "step": 460,
      "train_speed(iter/s)": 0.095433
    },
    {
      "acc": 0.86617393,
      "epoch": 3.136593591905565,
      "grad_norm": 2.453125,
      "learning_rate": 3.3237712783097004e-05,
      "loss": 0.58407817,
      "memory(GiB)": 67.16,
      "step": 465,
      "train_speed(iter/s)": 0.095423
    },
    {
      "acc": 0.86474743,
      "epoch": 3.1703204047217537,
      "grad_norm": 3.3125,
      "learning_rate": 3.218942734801118e-05,
      "loss": 0.6165874,
      "memory(GiB)": 67.16,
      "step": 470,
      "train_speed(iter/s)": 0.095412
    },
    {
      "acc": 0.86419888,
      "epoch": 3.204047217537943,
      "grad_norm": 2.28125,
      "learning_rate": 3.115003369721346e-05,
      "loss": 0.60770316,
      "memory(GiB)": 67.16,
      "step": 475,
      "train_speed(iter/s)": 0.09538
    },
    {
      "acc": 0.85879688,
      "epoch": 3.2377740303541316,
      "grad_norm": 2.671875,
      "learning_rate": 3.012005073957413e-05,
      "loss": 0.59620547,
      "memory(GiB)": 67.16,
      "step": 480,
      "train_speed(iter/s)": 0.095413
    },
    {
      "acc": 0.86981602,
      "epoch": 3.2715008431703203,
      "grad_norm": 2.84375,
      "learning_rate": 2.9099992685751014e-05,
      "loss": 0.60012369,
      "memory(GiB)": 67.16,
      "step": 485,
      "train_speed(iter/s)": 0.095458
    },
    {
      "acc": 0.87018299,
      "epoch": 3.305227655986509,
      "grad_norm": 2.375,
      "learning_rate": 2.809036879147401e-05,
      "loss": 0.56697874,
      "memory(GiB)": 67.16,
      "step": 490,
      "train_speed(iter/s)": 0.095527
    },
    {
      "acc": 0.86447144,
      "epoch": 3.338954468802698,
      "grad_norm": 3.0,
      "learning_rate": 2.7091683103303288e-05,
      "loss": 0.60214348,
      "memory(GiB)": 67.16,
      "step": 495,
      "train_speed(iter/s)": 0.09555
    },
    {
      "acc": 0.87294807,
      "epoch": 3.372681281618887,
      "grad_norm": 3.296875,
      "learning_rate": 2.6104434206988147e-05,
      "loss": 0.58250971,
      "memory(GiB)": 67.16,
      "step": 500,
      "train_speed(iter/s)": 0.09557
    },
    {
      "acc": 0.8610733,
      "epoch": 3.4064080944350756,
      "grad_norm": 2.78125,
      "learning_rate": 2.512911497855207e-05,
      "loss": 0.60171499,
      "memory(GiB)": 67.16,
      "step": 505,
      "train_speed(iter/s)": 0.09561
    },
    {
      "acc": 0.87625017,
      "epoch": 3.440134907251265,
      "grad_norm": 2.421875,
      "learning_rate": 2.4166212338228383e-05,
      "loss": 0.54478893,
      "memory(GiB)": 67.16,
      "step": 510,
      "train_speed(iter/s)": 0.095642
    },
    {
      "acc": 0.884618,
      "epoch": 3.4738617200674535,
      "grad_norm": 2.96875,
      "learning_rate": 2.3216207007369247e-05,
      "loss": 0.50501361,
      "memory(GiB)": 67.16,
      "step": 515,
      "train_speed(iter/s)": 0.095628
    },
    {
      "acc": 0.88286304,
      "epoch": 3.5075885328836423,
      "grad_norm": 2.921875,
      "learning_rate": 2.2279573268449443e-05,
      "loss": 0.50647125,
      "memory(GiB)": 67.16,
      "step": 520,
      "train_speed(iter/s)": 0.095641
    },
    {
      "acc": 0.88600063,
      "epoch": 3.5413153456998314,
      "grad_norm": 3.625,
      "learning_rate": 2.135677872828467e-05,
      "loss": 0.52074385,
      "memory(GiB)": 67.16,
      "step": 525,
      "train_speed(iter/s)": 0.095689
    },
    {
      "acc": 0.89183044,
      "epoch": 3.57504215851602,
      "grad_norm": 3.4375,
      "learning_rate": 2.0448284084582625e-05,
      "loss": 0.49923954,
      "memory(GiB)": 67.16,
      "step": 530,
      "train_speed(iter/s)": 0.095706
    },
    {
      "acc": 0.88213844,
      "epoch": 3.608768971332209,
      "grad_norm": 7.96875,
      "learning_rate": 1.9554542895943363e-05,
      "loss": 0.51344438,
      "memory(GiB)": 67.16,
      "step": 535,
      "train_speed(iter/s)": 0.095715
    },
    {
      "acc": 0.88883972,
      "epoch": 3.642495784148398,
      "grad_norm": 2.640625,
      "learning_rate": 1.8676001355423893e-05,
      "loss": 0.49681215,
      "memory(GiB)": 67.16,
      "step": 540,
      "train_speed(iter/s)": 0.095708
    },
    {
      "acc": 0.88804188,
      "epoch": 3.6762225969645868,
      "grad_norm": 2.9375,
      "learning_rate": 1.7813098067779948e-05,
      "loss": 0.47414827,
      "memory(GiB)": 67.16,
      "step": 545,
      "train_speed(iter/s)": 0.095695
    },
    {
      "acc": 0.88351278,
      "epoch": 3.7099494097807755,
      "grad_norm": 2.671875,
      "learning_rate": 1.6966263830495936e-05,
      "loss": 0.50225701,
      "memory(GiB)": 67.16,
      "step": 550,
      "train_speed(iter/s)": 0.095649
    },
    {
      "acc": 0.88836823,
      "epoch": 3.7436762225969646,
      "grad_norm": 2.9375,
      "learning_rate": 1.6135921418712956e-05,
      "loss": 0.49437485,
      "memory(GiB)": 67.16,
      "step": 555,
      "train_speed(iter/s)": 0.095655
    },
    {
      "acc": 0.89030161,
      "epoch": 3.7774030354131534,
      "grad_norm": 2.703125,
      "learning_rate": 1.5322485374161626e-05,
      "loss": 0.47958031,
      "memory(GiB)": 67.16,
      "step": 560,
      "train_speed(iter/s)": 0.095636
    },
    {
      "acc": 0.89285336,
      "epoch": 3.811129848229342,
      "grad_norm": 2.625,
      "learning_rate": 1.4526361798205596e-05,
      "loss": 0.46581626,
      "memory(GiB)": 67.16,
      "step": 565,
      "train_speed(iter/s)": 0.095662
    },
    {
      "acc": 0.89823847,
      "epoch": 3.8448566610455313,
      "grad_norm": 3.125,
      "learning_rate": 1.3747948149098538e-05,
      "loss": 0.44200172,
      "memory(GiB)": 67.16,
      "step": 570,
      "train_speed(iter/s)": 0.095675
    },
    {
      "acc": 0.89629936,
      "epoch": 3.87858347386172,
      "grad_norm": 3.109375,
      "learning_rate": 1.2987633043556507e-05,
      "loss": 0.45473509,
      "memory(GiB)": 67.16,
      "step": 575,
      "train_speed(iter/s)": 0.095682
    },
    {
      "acc": 0.88928909,
      "epoch": 3.9123102866779087,
      "grad_norm": 3.515625,
      "learning_rate": 1.2245796062744102e-05,
      "loss": 0.49689689,
      "memory(GiB)": 67.16,
      "step": 580,
      "train_speed(iter/s)": 0.095679
    },
    {
      "acc": 0.89579172,
      "epoch": 3.946037099494098,
      "grad_norm": 3.34375,
      "learning_rate": 1.1522807562771675e-05,
      "loss": 0.44178495,
      "memory(GiB)": 67.16,
      "step": 585,
      "train_speed(iter/s)": 0.095681
    },
    {
      "acc": 0.89893398,
      "epoch": 3.9797639123102866,
      "grad_norm": 2.6875,
      "learning_rate": 1.0819028489798005e-05,
      "loss": 0.41400328,
      "memory(GiB)": 67.16,
      "step": 590,
      "train_speed(iter/s)": 0.095696
    },
    {
      "acc": 0.90257616,
      "epoch": 4.013490725126475,
      "grad_norm": 3.015625,
      "learning_rate": 1.013481019983088e-05,
      "loss": 0.40472946,
      "memory(GiB)": 67.16,
      "step": 595,
      "train_speed(iter/s)": 0.095691
    },
    {
      "acc": 0.90990686,
      "epoch": 4.0472175379426645,
      "grad_norm": 2.9375,
      "learning_rate": 9.47049428331545e-06,
      "loss": 0.3666002,
      "memory(GiB)": 67.16,
      "step": 600,
      "train_speed(iter/s)": 0.095715
    },
    {
      "acc": 0.9053607,
      "epoch": 4.080944350758854,
      "grad_norm": 2.9375,
      "learning_rate": 8.826412394597905e-06,
      "loss": 0.40142307,
      "memory(GiB)": 67.16,
      "step": 605,
      "train_speed(iter/s)": 0.095717
    },
    {
      "acc": 0.91402588,
      "epoch": 4.114671163575042,
      "grad_norm": 3.640625,
      "learning_rate": 8.202886086349848e-06,
      "loss": 0.34803066,
      "memory(GiB)": 67.16,
      "step": 610,
      "train_speed(iter/s)": 0.095729
    },
    {
      "acc": 0.90690384,
      "epoch": 4.148397976391231,
      "grad_norm": 2.953125,
      "learning_rate": 7.600226649035619e-06,
      "loss": 0.38505411,
      "memory(GiB)": 67.16,
      "step": 615,
      "train_speed(iter/s)": 0.095792
    },
    {
      "acc": 0.9096199,
      "epoch": 4.18212478920742,
      "grad_norm": 3.359375,
      "learning_rate": 7.018734955503048e-06,
      "loss": 0.37522573,
      "memory(GiB)": 67.16,
      "step": 620,
      "train_speed(iter/s)": 0.095788
    },
    {
      "acc": 0.91042719,
      "epoch": 4.2158516020236085,
      "grad_norm": 4.25,
      "learning_rate": 6.458701310775184e-06,
      "loss": 0.35576253,
      "memory(GiB)": 67.16,
      "step": 625,
      "train_speed(iter/s)": 0.09578
    },
    {
      "acc": 0.90977755,
      "epoch": 4.249578414839798,
      "grad_norm": 2.671875,
      "learning_rate": 5.92040530711786e-06,
      "loss": 0.37619915,
      "memory(GiB)": 67.16,
      "step": 630,
      "train_speed(iter/s)": 0.0958
    },
    {
      "acc": 0.90839739,
      "epoch": 4.283305227655987,
      "grad_norm": 2.796875,
      "learning_rate": 5.4041156844554295e-06,
      "loss": 0.37822366,
      "memory(GiB)": 67.16,
      "step": 635,
      "train_speed(iter/s)": 0.095789
    },
    {
      "acc": 0.90891628,
      "epoch": 4.317032040472175,
      "grad_norm": 2.765625,
      "learning_rate": 4.910090196204626e-06,
      "loss": 0.3665164,
      "memory(GiB)": 67.16,
      "step": 640,
      "train_speed(iter/s)": 0.095797
    },
    {
      "acc": 0.91095524,
      "epoch": 4.350758853288364,
      "grad_norm": 2.671875,
      "learning_rate": 4.43857548059321e-06,
      "loss": 0.36035404,
      "memory(GiB)": 67.16,
      "step": 645,
      "train_speed(iter/s)": 0.095806
    },
    {
      "acc": 0.91495628,
      "epoch": 4.3844856661045535,
      "grad_norm": 2.75,
      "learning_rate": 3.989806937527868e-06,
      "loss": 0.38664653,
      "memory(GiB)": 67.16,
      "step": 650,
      "train_speed(iter/s)": 0.095828
    },
    {
      "acc": 0.91127758,
      "epoch": 4.418212478920742,
      "grad_norm": 2.984375,
      "learning_rate": 3.5640086110726336e-06,
      "loss": 0.37005782,
      "memory(GiB)": 67.16,
      "step": 655,
      "train_speed(iter/s)": 0.095841
    },
    {
      "acc": 0.91980915,
      "epoch": 4.451939291736931,
      "grad_norm": 2.859375,
      "learning_rate": 3.161393077596797e-06,
      "loss": 0.3381568,
      "memory(GiB)": 67.16,
      "step": 660,
      "train_speed(iter/s)": 0.095884
    },
    {
      "acc": 0.89891329,
      "epoch": 4.48566610455312,
      "grad_norm": 2.984375,
      "learning_rate": 2.78216133964781e-06,
      "loss": 0.41629057,
      "memory(GiB)": 67.16,
      "step": 665,
      "train_speed(iter/s)": 0.095868
    },
    {
      "acc": 0.91715298,
      "epoch": 4.519392917369308,
      "grad_norm": 2.9375,
      "learning_rate": 2.4265027256024196e-06,
      "loss": 0.3426121,
      "memory(GiB)": 67.16,
      "step": 670,
      "train_speed(iter/s)": 0.095879
    },
    {
      "acc": 0.91973906,
      "epoch": 4.5531197301854975,
      "grad_norm": 2.734375,
      "learning_rate": 2.0945947951459875e-06,
      "loss": 0.33373599,
      "memory(GiB)": 67.16,
      "step": 675,
      "train_speed(iter/s)": 0.09585
    },
    {
      "acc": 0.91285,
      "epoch": 4.586846543001687,
      "grad_norm": 2.65625,
      "learning_rate": 1.7866032506272778e-06,
      "loss": 0.34150867,
      "memory(GiB)": 67.16,
      "step": 680,
      "train_speed(iter/s)": 0.095852
    },
    {
      "acc": 0.91398268,
      "epoch": 4.620573355817875,
      "grad_norm": 3.34375,
      "learning_rate": 1.5026818543328825e-06,
      "loss": 0.37632542,
      "memory(GiB)": 67.16,
      "step": 685,
      "train_speed(iter/s)": 0.095827
    },
    {
      "acc": 0.91162233,
      "epoch": 4.654300168634064,
      "grad_norm": 2.8125,
      "learning_rate": 1.2429723517226211e-06,
      "loss": 0.37084935,
      "memory(GiB)": 67.16,
      "step": 690,
      "train_speed(iter/s)": 0.095877
    },
    {
      "acc": 0.91024399,
      "epoch": 4.688026981450253,
      "grad_norm": 3.265625,
      "learning_rate": 1.007604400664347e-06,
      "loss": 0.38558571,
      "memory(GiB)": 67.16,
      "step": 695,
      "train_speed(iter/s)": 0.095849
    },
    {
      "acc": 0.90761833,
      "epoch": 4.721753794266442,
      "grad_norm": 3.28125,
      "learning_rate": 7.966955067032101e-07,
      "loss": 0.36786571,
      "memory(GiB)": 67.16,
      "step": 700,
      "train_speed(iter/s)": 0.095839
    },
    {
      "acc": 0.919697,
      "epoch": 4.755480607082631,
      "grad_norm": 2.78125,
      "learning_rate": 6.10350964398021e-07,
      "loss": 0.32225547,
      "memory(GiB)": 67.16,
      "step": 705,
      "train_speed(iter/s)": 0.095827
    },
    {
      "acc": 0.91128311,
      "epoch": 4.78920741989882,
      "grad_norm": 2.96875,
      "learning_rate": 4.4866380475377947e-07,
      "loss": 0.37260132,
      "memory(GiB)": 67.16,
      "step": 710,
      "train_speed(iter/s)": 0.095828
    },
    {
      "acc": 0.90739193,
      "epoch": 4.822934232715008,
      "grad_norm": 3.421875,
      "learning_rate": 3.1171474877670914e-07,
      "loss": 0.41197581,
      "memory(GiB)": 67.16,
      "step": 715,
      "train_speed(iter/s)": 0.095818
    },
    {
      "acc": 0.91136551,
      "epoch": 4.856661045531197,
      "grad_norm": 3.265625,
      "learning_rate": 1.9957216717491067e-07,
      "loss": 0.3542125,
      "memory(GiB)": 67.16,
      "step": 720,
      "train_speed(iter/s)": 0.095798
    },
    {
      "acc": 0.91350327,
      "epoch": 4.8903878583473865,
      "grad_norm": 3.203125,
      "learning_rate": 1.1229204622489886e-07,
      "loss": 0.35618494,
      "memory(GiB)": 67.16,
      "step": 725,
      "train_speed(iter/s)": 0.09577
    },
    {
      "acc": 0.92251902,
      "epoch": 4.924114671163575,
      "grad_norm": 2.71875,
      "learning_rate": 4.9917959820855454e-08,
      "loss": 0.31488562,
      "memory(GiB)": 67.16,
      "step": 730,
      "train_speed(iter/s)": 0.095795
    },
    {
      "acc": 0.90866013,
      "epoch": 4.957841483979764,
      "grad_norm": 2.546875,
      "learning_rate": 1.2481047720735995e-08,
      "loss": 0.35094905,
      "memory(GiB)": 67.16,
      "step": 735,
      "train_speed(iter/s)": 0.095783
    },
    {
      "acc": 0.91885939,
      "epoch": 4.991568296795953,
      "grad_norm": 2.75,
      "learning_rate": 0.0,
      "loss": 0.33401127,
      "memory(GiB)": 67.16,
      "step": 740,
      "train_speed(iter/s)": 0.095735
    },
    {
      "epoch": 4.991568296795953,
      "eval_acc": 0.7884615384615384,
      "eval_loss": 1.2863396406173706,
      "eval_runtime": 6.4922,
      "eval_samples_per_second": 7.239,
      "eval_steps_per_second": 0.924,
      "step": 740
    }
  ],
  "logging_steps": 5,
  "max_steps": 740,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
