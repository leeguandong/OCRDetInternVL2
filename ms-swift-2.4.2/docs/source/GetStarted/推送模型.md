
# 推送模型

使用SWIFT时，用户可以选择将训练好的模型推送到魔搭社区上。

要使用推送模型能力，首先要确认你已经注册了魔搭官方账号，并且在[页面](https://www.modelscope.cn/my/myaccesstoken)上取得了对应的sdk token。

## 训练时推送模型

在训练时推送模型，需要在命令行上添加以下参数：
```shell
--push_to_hub true \
--hub_model_id my-group/my-model \
--hub_token <token-from-modelscope-page>
```

上述参数添加好后，训练后的checkpoint和训练参数就会被推送到魔搭社区上，方便以后使用。值得注意的是，魔搭社区允许您上传私有模型，需要模型是私有时，添加以下参数:

```shell
--hub_private_repo true
```

这样该模型就只有有该组织权限的人才能看到。

## 导出时推送模型

导出时推送模型的参数和训练时的参数是相同的：
```shell
CUDA_VISIBLE_DEVICES=0 swift export \
    --ckpt_dir output/qwen1half-4b-chat/vx-xxx/checkpoint-xxx \
    --push_to_hub true \
    --hub_model_id qwen1half-4b-chat-lora \
    --hub_token '<your-sdk-token>'
```

这样可以将LoRA合并或量化后的模型直接推送到魔搭上。
